{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data', train=True, transform=T.ToTensor(), download=True)\n",
    "image, label = train_dataset[0]\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image, label = train_dataset[1]\n",
    "print(image.shape)\n",
    "print(label)\n",
    "\n",
    "# (c, h, w) -> (h, w, c)\n",
    "image = image.permute(1, 2, 0)\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.model import Unet\n",
    "\n",
    "bs = 32\n",
    "ch = 1\n",
    "size = 32\n",
    "timestep = 5000\n",
    "down_chs = (8, 16, 32, 64, 64)\n",
    "lr = 2e-4\n",
    "epochs = 3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Unet(ch, size, down_chs, timestep).to(device)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405329"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(image):\n",
    "    image = image.squeeze(0).cpu()\n",
    "        \n",
    "    # (c, h, w) -> (h, w, c)\n",
    "    image = image.permute(1, 2, 0)\n",
    "    image = torch.clip(image, 0, 1)\n",
    "\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x64 and 256x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, timestep, (bs_dim, ), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/raid/mg/diffusion/DDPM/models/model.py:165\u001b[0m, in \u001b[0;36mUnet.get_loss\u001b[0;34m(self, input, t)\u001b[0m\n\u001b[1;32m    162\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m alphas_bar_t\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alphas_bar_t)\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m*\u001b[39m noise\n\u001b[0;32m--> 165\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m#loss = F.mse_loss(pred, noise)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m loss \u001b[38;5;241m=\u001b[39m (noise \u001b[38;5;241m-\u001b[39m pred)\u001b[38;5;241m.\u001b[39msquare()\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/raid/mg/diffusion/DDPM/models/model.py:145\u001b[0m, in \u001b[0;36mUnet.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    142\u001b[0m latent_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_vec(down4)\n\u001b[1;32m    144\u001b[0m t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m timestep\n\u001b[0;32m--> 145\u001b[0m latent_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m temb_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemb_1(t)\n\u001b[1;32m    147\u001b[0m temb_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemb_2(t)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x64 and 256x64)"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "samples = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loader = tqdm(train_loader)\n",
    "    \n",
    "    for step, batch in enumerate(loader):\n",
    "        image, label = batch\n",
    "        \n",
    "        bs_dim = image.shape[0]\n",
    "        \n",
    "        image = image.to(device)\n",
    "        t = torch.randint(0, timestep, (bs_dim, ), device=device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = model.get_loss(image, t)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        loader.set_description(f'Epoch {epoch} | step: {step} | loss: {loss.item():.4f}')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sample = model.sampling()\n",
    "        samples.append(sample)\n",
    "        sample_image(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
